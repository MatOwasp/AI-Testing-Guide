# 3. AI Testing Guide Framework

Based on the Threat modeling performed at Chapert 2, we can now define a structured framework that maps the most critical security and trustworthy AI threats to concrete test cases. This project aims to bridge traditional cybersecurity, MLOps testing, and Responsible AI assessments under a unified structure.

Each test case is categorized under one of the four pillars, based on the threat modeling we did perform in the previous chapters:

- ðŸŸ¦ **AI Application Testing**
- ðŸŸª **AI Model Testing**
- ðŸŸ© **AI Infrastructure Testing**
- ðŸŸ¨ **AI Data Testing**

---

The following are the list of tests to perform:

### ðŸŸ¦ [AI Application Testing](./tests/AI_APPLICATION_TESTING.md)
| Test ID       | Test Name                                |
|---------------|-------------------------------------------|
| AITG-APP-01   | [Testing for Prompt Injection](https://github.com/MatOwasp/AI-Testing-Guide/blob/main/Document/content/tests/AITG-APP-01_Testing_for_Prompt_Injection.md)              |
| AITG-APP-02   | Testing for Indirect Prompt Injection     |
| AITG-APP-03   | Testing for Sensitive Data Leak           |
| AITG-APP-04   | Testing for Input Leakage                 |
| AITG-APP-05   | Testing for Unsafe Outputs                |
| AITG-APP-06   | Testing for Agentic Behavior Limits       |
| AITG-APP-07   | Testing for Prompt Disclosure             |
| AITG-APP-08   | Testing for Embedding Manipulation        |
| AITG-APP-09   | Testing for Model Extraction              |
| AITG-APP-10   | Testing for Harmful Content Bias          |
| AITG-APP-11   | Testing for Hallucinations                |
| AITG-APP-12   | Testing for Toxic Output                  |
| AITG-APP-13   | Testing for Over-Reliance on AI           |
| AITG-APP-14   | Testing for Explainability and Interpretability |

---

### ðŸŸª [AI Model Testing](./tests/AI_MODEL_TESTING.md)
| Test ID       | Test Name                                |
|---------------|-------------------------------------------|
| AITG-MOD-01   | Testing for Evasion Attacks               |
| AITG-MOD-02   | Testing for Runtime Model Poisoning       |
| AITG-MOD-03   | Testing for Poisoned Training Sets        |
| AITG-MOD-04   | Testing for Fine-tuning Poisoning         |
| AITG-MOD-05   | Testing for Membership Inference          |
| AITG-MOD-06   | Testing for Inversion Attacks             |
| AITG-MOD-07   | Testing for Robustness to New Data        |
| AITG-MOD-08   | Testing for Goal Alignment                |

---

### ðŸŸ© [AI Infrastructure Testing](./tests/AI_INFRASTRUCTURE_TESTING.md)
| Test ID       | Test Name                                |
|---------------|-------------------------------------------|
| AITG-INF-01   | Testing for Supply Chain Tampering        |
| AITG-INF-02   | Testing for Resource Exhaustion           |
| AITG-INF-03   | Testing for Plugin Boundary Violations    |
| AITG-INF-04   | Testing for Capability Misuse             |
| AITG-INF-05   | Testing for Fine-tuning Poisoning         |
| AITG-INF-06   | Testing for Dev-Time Model Theft          |

---

### ðŸŸ¨ [AI Data Testing](./tests/AI_DATA_TESTING.md)
| Test ID       | Test Name                                |
|---------------|-------------------------------------------|
| AITG-DAT-01   | Testing for Training Data Exposure        |
| AITG-DAT-03   | Testing for Runtime Exfiltration          |
| AITG-DAT-05   | Testing for Dataset Diversity & Coverage  |
| AITG-DAT-06   | Testing for Harmful Content in Data       |
| AITG-DAT-07   | Testing for Data Minimization & Consent   |

NEXT:
[3.1 Testing for Prompt Injection](https://github.com/MatOwasp/AI-Testing-Guide/blob/main/Document/content/tests/AITG-APP-01_Testing_for_Prompt_Injection.md)     
[Table of Content](README.md)
