

## Mapping the OWASP Threats of AI Architecture

### What We Did

We performed a threat modeling over a modular AI architecture (based on Googleâ€™s [Secure AI Framework](https://saif.google/secure-ai-framework/saif-map)), visually identifying where AI-specific threats apply across the data, infrastructure, model, and application layers.

Our goal was to start mapping the onto concrete components of the architecture, as seen in this diagram:
- The OWASP Top 10 LLM Risks 2025
- OWASP AI Exchange Threats 

The following is a visual map of threats on the AI Syteemt Architecture:

<p align="center">
  <img src="/images/AIarchitectureTM.png" alt="AI Architecture Threat Model" width="1200"/>
</p>

---

## OWASP Threat Mapping Table

| # | OWASP Threat Name | Short Name | Source | [URL | Test Name |
|--:|--------------------|------------|--------|----------|---------------------|
| 1 | Prompt Injection | LLM01 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm01/) | Testing for Prompt Injection |
| 2 | Indirect Prompt Injection | LLM01 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm01/) | Testing for Indirect Prompt Injection |
| 3 | Adversarial Input (Evasion) | Threat 2.1 | OWASP AI Exchange | [link](https://owaspai.org/docs/2_threats_through_use/#21-adversarial-input-evasion) | Testing for Evasion Attacks |
| 4 | Runtime Model Poisoning | LLM04 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm04/) | Testing for Runtime Model Poisoning |
| 5 | Training Data Poisoning | LLM04 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm04/) | Testing for Poisoned Training Sets |
| 6 | Data Poisoning during Fine-tuning | LLM04 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm04/) | Testing for Fine-tuning Poisoning |
| 7 | Supply Chain Model Poisoning | LLM03 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm03/) | Testing for Supply Chain Tampering |
| 8 | Sensitive Information Disclosure | LLM02 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm02/) | Testing for Sensitive Data Leak |
| 9 | Model Inversion & Membership Inference | Threat 2.4 | OWASP AI Exchange | [link](https://owaspai.org/docs/2_threats_through_use/#24-training-set-membership-inference) | Testing for Membership Inference |
| 10 | Training Data Leakage | Threat 2.5 | OWASP AI Exchange | [link](https://owaspai.org/docs/2_threats_through_use/#25-training-data-leakage) | Testing for Training Data Exposure |
| 11 | Model Theft via Use (API Reversal) | Threat 2.3 | OWASP AI Exchange | [link](https://owaspai.org/docs/2_threats_through_use/#23-model-reversal) | Testing for Model Extraction |
| 12 | Model Theft at Runtime | Threat 2.2 | OWASP AI Exchange | [link](https://owaspai.org/docs/2_threats_through_use/#22-model-exfiltration) | Testing for Runtime Exfiltration |
| 13 | Model Theft during Development | LLM02 / Threat 2.2 | Both | [Top 10](https://genai.owasp.org/llm02/) / [AI Exchange](https://owaspai.org/docs/2_threats_through_use/#22-model-exfiltration) | Testing for Dev-Time Model Theft |
| 14 | Denial of Model Services / Unbounded Consumption | LLM10 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm10/) | Testing for Resource Exhaustion |
| 15 | Sensitive Input Leaks | LLM02 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm02/) | Testing for Input Leakage |
| 16 | Improper Output Handling | LLM05 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm05/) | Testing for Unsafe Outputs |
| 17 | Excessive Agency | LLM06 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm06/) | Testing for Agentic Behavior Limits |
| 18 | System Prompt Leakage | LLM07 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm07/) | Testing for Prompt Disclosure |
| 19 | Vector & Embedding Weaknesses | LLM08 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm08/) | Testing for Embedding Manipulation |
| 20 | Misinformation Generation | LLM09 | OWASP Top 10 2025 | [link](https://genai.owasp.org/llm09/) | Testing for Harmful Content Bias |


